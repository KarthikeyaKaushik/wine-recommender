}
else{
log.likelihood[i] = -Inf
}
}
log.posterior = log.prior + log.likelihood
log.posterior = log.posterior - logsumexp(log.posterior)
# posterior predictive plot
predictive = rep(0,N)
for (n in 1:N){
# predictive[n] is the model's prediction about n,
# which is a weighted average over hypotheses
for (i in 1:length(H)){
predictive[n] = predictive[n] +
ifelse(is.element(n,H[[i]]), exp(log.posterior[i]), 0)
}
}
# 1.a metropolis sampler :
# the task is to sample between hypotheses, with the
# log.posterior acting as a proxy for f
samples = NULL
proposals = NULL
current = 1 # holds the current value of the hypothesis
# there's 10 hypotheses in all.
# the f here corresponds to the posterior prob
while (length(samples) < 1000){
proposed = sample(1:length(H), 1)
# accept the proposal with probability
# f(proposal)/f(current)
# if f(propoasl) > f(current), take it
# else take it with that probability !
if (log(runif(1)) < log.posterior[proposed] -
log.posterior[current]){
current = proposed}
# Warning : You should always keep current, because that will make
# sure you push it towards the max
samples = append(samples, current)
proposals = append(proposals, proposed)
}
# get rid of 30% of the samples
samples = samples[500:1000]
hist(samples, freq=F, xlim=c(1, length(H)),
breaks=seq(0,10))
# 1.b
# How often do they change hypotheses if they are running
# one metropolis step every 200 ms?
# it is the number of changes/total number of samples
# 1.b
# How often do they change hypotheses if they are running
# one metropolis step every 200 ms?
# it is the number of changes/total number of samples
count_change = 0
for (i in 2:length(samples)){
if (samples[i-1] != samples[i]){count_change =
count_change + 1}
}
switches = count_change/length(samples)
switches = 200/(count_change/length(samples))
install.packages("rstan", repos = c("https://mc-stan.org/r-packages/", getOption("repos")))
library("rstan") # observe startup messages
library(rstan)
fit = stab("class-6a.stan", data=list(h=10, t=5), iter=5000, chain=2)
fit = stan("class-6a.stan", data=list(h=10, t=5), iter=5000, chain=2)
seq(1,N,2)
seq(1,100,2)
N = 100
H = list(seq(1,N,1),
seq(1,N,2),
seq(0,N,2),
seq(0,N,5),
seq(0,N,10),
seq(0,N,3),
seq(0,N,7),
seq(0,N,11),
c(1,4,9,16,25,36,49,64,81),
c(2,3,5,7,11,13,17,19,23,29,31,37,41,43,
47,53,59,61,67,71,73,79,83,89,97),
c(2,4,8,16,32,64)
)
logsumexp <- function(x){
m <- max(x)
return(log(sum(exp(x-m)))+m)
}
data = c(10,20)
log.prior = rep(0, length(H))
log.likelihood = rep(NA, length(H))
for(i in 1:length(H)){
if (all(is.element(data, H[[i]]))){
log.likelihood[i] = -length(data) * log(length(H[[i]]))
}
else{
log.likelihood[i] = -Inf
}
}
log.posterior = log.prior + log.likelihood
log.posterior = log.posterior - logsumexp(log.posterior)
# 1.a metropolis sampler :
# the task is to sample between hypotheses, with the
# log.posterior acting as a proxy for f
samples = NULL
proposals = NULL
current = 1 # holds the current value of the hypothesis
# there's 10 hypotheses in all.
# the f here corresponds to the posterior prob
while (length(samples) < 1000){
proposed = sample(1:length(H), 1)
# accept the proposal with probability
# f(proposal)/f(current)
# if f(propoasl) > f(current), take it
# else take it with that probability !
if (log(runif(1)) < log.posterior[proposed] -
log.posterior[current]){
current = proposed}
# Warning : You should always keep current, because that will make
# sure you push it towards the max
samples = append(samples, current)
proposals = append(proposals, proposed)
}
# get rid of 50% of the samples
samples = samples[500:1000]
#hist(samples, freq=F, breaks = seq(1,10))
table(samples)
N = 100
H = list(seq(1,N,1),
seq(1,N,2),
seq(0,N,2),
seq(0,N,5),
seq(0,N,10),
seq(0,N,3),
seq(0,N,7),
seq(0,N,11),
c(1,4,9,16,25,36,49,64,81),
c(2,3,5,7,11,13,17,19,23,29,31,37,41,43,
47,53,59,61,67,71,73,79,83,89,97),
c(2,4,8,16,32,64)
)
logsumexp <- function(x){
m <- max(x)
return(log(sum(exp(x-m)))+m)
}
data = c(10,20)
log.prior = rep(0, length(H))
log.likelihood = rep(NA, length(H))
for(i in 1:length(H)){
if (all(is.element(data, H[[i]]))){
log.likelihood[i] = -length(data) * log(length(H[[i]]))
}
else{
log.likelihood[i] = -Inf
}
}
log.posterior = log.prior + log.likelihood
log.posterior = log.posterior - logsumexp(log.posterior)
# 1.a metropolis sampler :
# the task is to sample between hypotheses, with the
# log.posterior acting as a proxy for f
samples = NULL
proposals = NULL
current = 1 # holds the current value of the hypothesis
# there's 10 hypotheses in all.
# the f here corresponds to the posterior prob
while (length(samples) < 1000){
proposed = sample(1:length(H), 1)
# accept the proposal with probability
# f(proposal)/f(current)
# if f(propoasl) > f(current), take it
# else take it with that probability !
if (log(runif(1)) < log.posterior[proposed] -
log.posterior[current]){
current = proposed}
# Warning : You should always keep current, because that will make
# sure you push it towards the max
samples = append(samples, current)
proposals = append(proposals, proposed)
}
# get rid of 50% of the samples
samples = samples[500:1000]
#hist(samples, freq=F, breaks = seq(1,10))
df = as.data.frame(table(samples))
View(df)
remaining = c(1:10) - unique(df$samples)
unique(df$samples)
as.numeric(df$samples)
#hist(samples, freq=F, breaks = seq(1,10))
df = as.data.frame(table(samples, useNA = "ifany"))
View(df)
View(df)
#hist(samples, freq=F, breaks = seq(1,10))
df = as.data.frame(table(samples))
for (hyp in 1:10){
if (hyp !%in% df$samples){
for (hyp in 1:10){
if (hyp %!in% df$samples){
df = rbind(df, c(hyp, 0))
}
}
#hist(samples, freq=F, breaks = seq(1,10))
df = as.data.frame(table(samples))
for (hyp in 1:10){
if !(hyp %in% df$samples){
for (hyp in 1:10){
if ~(hyp %in% df$samples){
for (hyp in 1:10){
if (hyp %in% df$samples){
df = rbind(df, c(hyp, 0))
}
}
View(df)
#hist(samples, freq=F, breaks = seq(1,10))
df = as.data.frame(table(samples))
for (hyp in 1:10){
if (!(hyp %in% df$samples)){
df = rbind(df, c(hyp, 0))
}
}
View(df)
#hist(samples, freq=F, breaks = seq(1,10))
df = as.data.frame(table(samples))
for (hyp in 1:10){
if (!(hyp %in% df$samples)){
df = rbind(df, c(as.factor(hyp), 0))
}
}
View(df)
#hist(samples, freq=F, breaks = seq(1,10))
df = as.data.frame(table(samples))
df = as.numeric(df)
# get rid of 50% of the samples
samples = samples[500:1000]
N = 100
H = list(seq(1,N,1),
seq(1,N,2),
seq(0,N,2),
seq(0,N,5),
seq(0,N,10),
seq(0,N,3),
seq(0,N,7),
seq(0,N,11),
c(1,4,9,16,25,36,49,64,81),
c(2,3,5,7,11,13,17,19,23,29,31,37,41,43,
47,53,59,61,67,71,73,79,83,89,97),
c(2,4,8,16,32,64)
)
logsumexp <- function(x){
m <- max(x)
return(log(sum(exp(x-m)))+m)
}
data = c(10,20)
log.prior = rep(0, length(H))
log.likelihood = rep(NA, length(H))
for(i in 1:length(H)){
if (all(is.element(data, H[[i]]))){
log.likelihood[i] = -length(data) * log(length(H[[i]]))
}
else{
log.likelihood[i] = -Inf
}
}
log.posterior = log.prior + log.likelihood
log.posterior = log.posterior - logsumexp(log.posterior)
# 1.a metropolis sampler :
# the task is to sample between hypotheses, with the
# log.posterior acting as a proxy for f
samples = NULL
proposals = NULL
current = 1 # holds the current value of the hypothesis
# there's 10 hypotheses in all.
# the f here corresponds to the posterior prob
while (length(samples) < 1000){
proposed = sample(1:length(H), 1)
# accept the proposal with probability
# f(proposal)/f(current)
# if f(propoasl) > f(current), take it
# else take it with that probability !
if (log(runif(1)) < log.posterior[proposed] -
log.posterior[current]){
current = proposed}
# Warning : You should always keep current, because that will make
# sure you push it towards the max
samples = append(samples, current)
proposals = append(proposals, proposed)
}
# get rid of 50% of the samples
samples = samples[500:1000]
#hist(samples, freq=F, breaks = seq(1,10))
df = as.data.frame(table(samples))
df$samples = as.numeric(df$samples)
View(df)
#hist(samples, freq=F, breaks = seq(1,10))
df = as.data.frame(as.numeric(table(samples)))
View(df)
#hist(samples, freq=F, breaks = seq(1,10))
df = as.data.frame(table(samples))
View(df)
N = 100
H = list(seq(1,N,1),
seq(1,N,2),
seq(0,N,2),
seq(0,N,5),
seq(0,N,10),
seq(0,N,3),
seq(0,N,7),
seq(0,N,11),
c(1,4,9,16,25,36,49,64,81),
c(2,3,5,7,11,13,17,19,23,29,31,37,41,43,
47,53,59,61,67,71,73,79,83,89,97),
c(2,4,8,16,32,64)
)
logsumexp <- function(x){
m <- max(x)
return(log(sum(exp(x-m)))+m)
}
data = c(10,20)
log.prior = rep(0, length(H))
log.likelihood = rep(NA, length(H))
for(i in 1:length(H)){
if (all(is.element(data, H[[i]]))){
log.likelihood[i] = -length(data) * log(length(H[[i]]))
}
else{
log.likelihood[i] = -Inf
}
}
log.posterior = log.prior + log.likelihood
log.posterior = log.posterior - logsumexp(log.posterior)
# 1.a metropolis sampler :
# the task is to sample between hypotheses, with the
# log.posterior acting as a proxy for f
samples = NULL
proposals = NULL
current = 1 # holds the current value of the hypothesis
# there's 10 hypotheses in all.
# the f here corresponds to the posterior prob
while (length(samples) < 1000){
proposed = sample(1:length(H), 1)
# accept the proposal with probability
# f(proposal)/f(current)
# if f(propoasl) > f(current), take it
# else take it with that probability !
if (log(runif(1)) < log.posterior[proposed] -
log.posterior[current]){
current = proposed}
# Warning : You should always keep current, because that will make
# sure you push it towards the max
samples = append(samples, current)
proposals = append(proposals, proposed)
}
# get rid of 50% of the samples
samples = samples[500:1000]
#hist(samples, freq=F, breaks = seq(1,10))
df = as.data.frame(table(samples))
df$samples = as.numeric(df$samples)
View(df)
N = 100
H = list(seq(1,N,1),
seq(1,N,2),
seq(0,N,2),
seq(0,N,5),
seq(0,N,10),
seq(0,N,3),
seq(0,N,7),
seq(0,N,11),
c(1,4,9,16,25,36,49,64,81),
c(2,3,5,7,11,13,17,19,23,29,31,37,41,43,
47,53,59,61,67,71,73,79,83,89,97),
c(2,4,8,16,32,64)
)
logsumexp <- function(x){
m <- max(x)
return(log(sum(exp(x-m)))+m)
}
data = c(10,20)
log.prior = rep(0, length(H))
log.likelihood = rep(NA, length(H))
for(i in 1:length(H)){
if (all(is.element(data, H[[i]]))){
log.likelihood[i] = -length(data) * log(length(H[[i]]))
}
else{
log.likelihood[i] = -Inf
}
}
log.posterior = log.prior + log.likelihood
log.posterior = log.posterior - logsumexp(log.posterior)
# 1.a metropolis sampler :
# the task is to sample between hypotheses, with the
# log.posterior acting as a proxy for f
samples = NULL
proposals = NULL
current = 1 # holds the current value of the hypothesis
# there's 10 hypotheses in all.
# the f here corresponds to the posterior prob
while (length(samples) < 1000){
proposed = sample(1:length(H), 1)
# accept the proposal with probability
# f(proposal)/f(current)
# if f(propoasl) > f(current), take it
# else take it with that probability !
if (log(runif(1)) < log.posterior[proposed] -
log.posterior[current]){
current = proposed}
# Warning : You should always keep current, because that will make
# sure you push it towards the max
samples = append(samples, current)
proposals = append(proposals, proposed)
}
# get rid of 50% of the samples
samples = samples[500:1000]
#hist(samples, freq=F, breaks = seq(1,10))
df = as.data.frame(table(samples))
View(df)
#df$samples = as.numeric(df$samples)
for (hyp in 1:10){
if (!(hyp %in% df$samples)){
df = rbind(df, c(hyp, 0))
}
}
View(df)
#hist(samples, freq=F, breaks = seq(1,10))
df = as.data.frame(table(samples))
df$samples = as.character(df$samples)
View(df)
#hist(samples, freq=F, breaks = seq(1,10))
df = as.data.frame(table(samples))
df$samples = as.numeric(as.character(df$samples))
View(df)
for (hyp in 1:10){
if (!(hyp %in% df$samples)){
df = rbind(df, c(hyp, 0))
}
}
View(df)
ggplot(data=df, aes(x=samples, y=freq)) + geom_bar()
plt = ggplot(data=df, aes(x=samples, y=freq)) + geom_bar()
library(ggplot2)
ggplot(data=df, aes(x=samples, y=freq)) + geom_bar()
View(df)
ggplot(data=df, aes(x=samples, y=Freq)) + geom_bar()
ggplot(data=df, aes(x=samples)) + geom_bar()
help(geom_bar)
ggplot(data=df, aes(x=samples)) + geom_bar(fill=Freq)
View(df)
View(df)
ggplot(data=df) + geom_bar(x=samples, fill=Freq)
t = ggplot(data=df) + geom_bar(x=samples, fill=Freq)
plot(t)
t = ggplot(data=df) + geom_bar(x=samples, fill=Freq)
t = ggplot(data=df) + geom_bar(x=samples)
t
t = ggplot(data=df) + geom_bar(x=samples, y=Freq)
View(df)
colnames(df) = c('Hypothesis', 'Frequency')
t = ggplot(data=df) + geom_bar(x=Hypothesis, y=Frequency)
View(df)
df = as.data.frame(df)
t = ggplot(data=df) + geom_bar(x=Hypothesis, y=Frequency)
t = ggplot(data=df) + geom_bar(aes(x=Hypothesis, y=Frequency))
t
t = ggplot(data=df) + geom_bar(aes(x=Hypothesis, fill=Frequency))
t
t = ggplot(data=df, aes(x=Hypothesis, y=Frequency)) + geom_bar(stat='identity')
t
ggplot(data=df, aes(x=Hypothesis, y=Frequency)) + geom_bar(stat='identity')
ggplot(data=df, aes(x=Hypothesis, y=Frequency)) + geom_bar(stat='identity') + theme_bw()
help(theme)
ggplot(data=df, aes(x=Hypothesis, y=Frequency)) + geom_bar(stat='identity') + theme_bw(axis.ticks.x = seq(1,10))
ggplot(data=df, aes(x=Hypothesis, y=Frequency)) + geom_bar(stat='identity') +
theme_bw(axis.ticks.x = seq(1,10))
ggplot(data=df, aes(x=Hypothesis, y=Frequency)) + geom_bar(stat='identity') +
theme(axis.ticks.x = seq(1,10)) + theme_bw()
ggplot(data=df, aes(x=Hypothesis, y=Frequency)) + geom_bar(stat='identity') +
theme(axis.ticks.x = seq(1,10,1)) + theme_bw()
library(ggplot2)
library(viridis)
library(gridExtra)
library(data.table)
library(matrixStats)
library(ggrepel)
homophily_df = read.table(file.path('results','homophily','both',
'individual.csv'),header=TRUE,sep=',')
setwd("~/Documents/Documents/projects/wine-recommender")
library(ggplot2)
library(viridis)
library(grid)
library(gridExtra)
library(dplyr)
library(matrixStats)
library(ggrepel)
library(tidyr)
library(png)
NUM_EXPERTS = 14
NUM_AMATEURS = 120
NUM_TOTAL = 134
COLOR_START = 0.75
COLOR_END = 0.1
k = c(1,2,3,5,7,9,11,13,17,19,23,29,50,75,100,125,NUM_EXPERTS+NUM_AMATEURS-1)
rho = c(0,0.25,0.5,0.75,1,1.25,1.5)
#### Some prepping for visualization ####
# the parameters are 17 * 7, so choose k=5,rho=1, so choose 26
stats_df = read.table(file.path('results','stats.csv'),
header=TRUE,sep=',')
View(stats_df)
lm(formula = k_5_both ~ ratings + mean_corr, data = stats_df)
both_error = read.table(file.path('results','simulations',
'both','performance.csv'),header=FALSE,sep=' ')
stats_df$k_5_both = both_error[26, ]
stats_df$k_5_both = both_error[,26]
lm(formula = k_5_both ~ ratings + mean_corr, data = stats_df)
linear_model = lm(formula = k_5_both ~ ratings + mean_corr, data = stats_df)
linear_model.summary()
linear_model
summary(linear_model)
