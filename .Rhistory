legend.title = element_text(size = 14),
legend.text = element_text(size = 14)) +
scale_y_continuous(position = "right", limits=c(.5,.85)) +
theme(legend.key.size=unit(.25,'cm')) +
theme(axis.text=element_text(size=20),
axis.title=element_text(size=22))
g1 = ggplotGrob(grouped_accuracies)
g2 = ggplotGrob(acc_fig)
g = grid.arrange(g1,g2,nrow=1)
ggsave(file.path('results', 'visualization',
'fig_2.png'), g, scale=1.35)
#### Figures for main paper : figure 2a ####
both_error = read.table(file.path('results','simulations',
'both','performance.csv'),header=FALSE,sep=' ')
experts_error = read.table(file.path('results','simulations',
'experts','performance.csv'),header=FALSE,sep=' ')
amateurs_error = read.table(file.path('results','simulations',
'amateurs','performance.csv'),header=FALSE,sep=' ')
to_select = seq(5, dim(experts_error)[2], length(rho)) # select only those rhos == 1
mean_acc_e_e = colMeans(experts_error[1:NUM_EXPERTS,to_select],na.rm=T) # experts recommending experts
mean_acc_e_a = colMeans(experts_error[NUM_EXPERTS+1:NUM_TOTAL,to_select],na.rm=T) # ex reco amateurs
# delete e_e, e_a for k values > (NUM_EXPERTS -1)
mean_acc_e_e[9:17] = NA
mean_acc_e_a[9:17] = NA
mean_acc_a_e = colMeans(amateurs_error[1:NUM_EXPERTS,to_select],na.rm=T)
mean_acc_a_a = colMeans(amateurs_error[NUM_EXPERTS+1:NUM_TOTAL,to_select],na.rm=T)
mean_acc_b_e = colMeans(both_error[1:NUM_EXPERTS,to_select],na.rm=T)
mean_acc_b_a = colMeans(both_error[NUM_EXPERTS+1:NUM_TOTAL,to_select],na.rm=T)
mean_acc_all = as.data.frame(rbind(mean_acc_e_e, mean_acc_e_a,
mean_acc_a_e, mean_acc_a_a,
mean_acc_b_e, mean_acc_b_a))
colnames(mean_acc_all) = as.character(k)
mean_acc_all$reco_group = c('Experts only', 'Experts only',
'Amateurs only', 'Amateurs only',
'Both','Both')
mean_acc_all$reco_group <- factor(mean_acc_all$reco_group, levels = c("Amateurs only", "Experts only", "Both"))
mean_acc_all$stats_group = c('Expert', 'Amateur',
'Expert', 'Amateur',
'Expert', 'Amateur')
keycol = 'k_value'
valuecol = 'Accuracy'
longform_mean_acc_all = gather(mean_acc_all, 'k_value', 'Accuracy', as.character(k))
longform_mean_acc_all$k_value = factor(longform_mean_acc_all$k_value,
levels=as.character(k))
longform_mean_acc_all$k_value = strtoi(longform_mean_acc_all$k_value)
grouped_accuracies = ggplot(data=longform_mean_acc_all, aes(x=as.numeric(k_value), y=as.numeric(Accuracy))) +
geom_line(aes(linetype=reco_group, color=stats_group), size=1.5, alpha=.8) +
scale_linetype_manual(values=c("dotdash","solid", "dashed")) +
scale_color_viridis(option='A',begin=COLOR_START,
end=.2, discrete=TRUE) +
theme_bw() + labs(x='k nearest neighbours',y='Accuracy') +
scale_x_continuous(breaks = c(1,2,3,5,7,9,11,13,15,17,19),
limits = c(1,19),expand = c(0.02, 0.02)) +
theme(aspect.ratio =1,
legend.position = c(0.725,0.125),
legend.title = element_text(size = 14),
legend.text = element_text(size = 14),
legend.box="horizontal") +
scale_y_continuous(limits=c(.5,.85)) +
guides(color=guide_legend(title="User")) +
guides(linetype=guide_legend(title="Recommender")) +
theme(axis.text=element_text(size=20),
axis.title=element_text(size=22))
grouped_accuracies
#### Supplementary figures : figure 6 ####
both_error = read.table(file.path('results','simulations',
'both','performance.csv'),header=FALSE,sep=' ')
experts_error = read.table(file.path('results','simulations',
'experts','performance.csv'),header=FALSE,sep=' ')
amateurs_error = read.table(file.path('results','simulations',
'amateurs','performance.csv'),header=FALSE,sep=' ')
# pick out k = 3,5,9,13 for all errors
pick_indices = c(seq(2*length(rho)+1, (2*length(rho) + length(rho))),
seq(3*length(rho)+1, (3*length(rho) + length(rho))),
seq(5*length(rho)+1, (5*length(rho) + length(rho))),
seq(6*length(rho)+1, (6*length(rho) + length(rho))))
mean_acc_e_e = colMeans(experts_error[1:NUM_EXPERTS,pick_indices],na.rm=T) # experts recommending experts
mean_acc_e_a = colMeans(experts_error[NUM_EXPERTS+1:NUM_TOTAL,pick_indices],na.rm=T) # ex reco amateurs
mean_acc_a_e = colMeans(amateurs_error[1:NUM_EXPERTS,pick_indices],na.rm=T)
mean_acc_a_a = colMeans(amateurs_error[NUM_EXPERTS+1:NUM_TOTAL,pick_indices],na.rm=T)
mean_acc_b_e = colMeans(both_error[1:NUM_EXPERTS,pick_indices],na.rm=T)
mean_acc_b_a = colMeans(both_error[NUM_EXPERTS+1:NUM_TOTAL,pick_indices],na.rm=T)
mean_acc_all = as.data.frame(rbind(mean_acc_e_e, mean_acc_e_a,
mean_acc_a_e, mean_acc_a_a,
mean_acc_b_e, mean_acc_b_a))
mean_acc_all = as.matrix(mean_acc_all)
longform_mean_acc_all = data.frame()
reco_group = c('Experts only', 'Experts only',
'Amateurs only', 'Amateurs only',
'Both','Both')
stats_group = c('Expert', 'Amateur',
'Expert', 'Amateur',
'Expert', 'Amateur')
chosen_ks = c('k = 3','k = 5','k = 9','k = 13')
for (g_type in 1:dim(mean_acc_all)[1]){
for (r_value in 1:dim(mean_acc_all)[2]) {
longform_mean_acc_all = rbind(longform_mean_acc_all,
c(mean_acc_all[g_type, r_value],
reco_group[g_type],
stats_group[g_type],
rho[(r_value-1)%%length(rho) + 1],
chosen_ks[ceiling(r_value/length(rho))]))
}
}
colnames(longform_mean_acc_all) = c('Accuracy', 'reco_group', 'stats_group', 'rho_value', 'k_value')
longform_mean_acc_all$rho_value = as.double(longform_mean_acc_all$rho_value)
longform_mean_acc_all$k_value = factor(longform_mean_acc_all$k_value,
levels=chosen_ks)
grouped_accuracies = ggplot(data=longform_mean_acc_all,
aes(x=as.numeric(rho_value), y=as.numeric(Accuracy))) +
facet_wrap(vars(k_value), nrow=2, ncol=2) +
geom_line(aes(linetype=reco_group, color=stats_group), size=.8, alpha=.8) +
scale_linetype_manual(values=c("dotdash","solid", "dashed")) +
scale_color_viridis(option='A',begin=COLOR_START,
end=.2, discrete=TRUE) +
theme_bw() + labs(x='Weighting parameter (rho)',y='Accuracy') +
guides(color=guide_legend(title="User")) +
guides(linetype=guide_legend(title="Recommender")) +
theme(axis.text=element_text(size=20),
axis.title=element_text(size=22),
strip.text.x = element_text(size = 11),
legend.title = element_text(size = 14),
legend.text = element_text(size = 14))
grouped_accuracies
#### Figures for main paper : figure 2a ####
both_error = read.table(file.path('results','simulations',
'both','performance.csv'),header=FALSE,sep=' ')
experts_error = read.table(file.path('results','simulations',
'experts','performance.csv'),header=FALSE,sep=' ')
amateurs_error = read.table(file.path('results','simulations',
'amateurs','performance.csv'),header=FALSE,sep=' ')
to_select = seq(5, dim(experts_error)[2], length(rho)) # select only those rhos == 1
mean_acc_e_e = colMeans(experts_error[1:NUM_EXPERTS,to_select],na.rm=T) # experts recommending experts
mean_acc_e_a = colMeans(experts_error[NUM_EXPERTS+1:NUM_TOTAL,to_select],na.rm=T) # ex reco amateurs
# delete e_e, e_a for k values > (NUM_EXPERTS -1)
mean_acc_e_e[9:17] = NA
mean_acc_e_a[9:17] = NA
mean_acc_a_e = colMeans(amateurs_error[1:NUM_EXPERTS,to_select],na.rm=T)
mean_acc_a_a = colMeans(amateurs_error[NUM_EXPERTS+1:NUM_TOTAL,to_select],na.rm=T)
mean_acc_b_e = colMeans(both_error[1:NUM_EXPERTS,to_select],na.rm=T)
mean_acc_b_a = colMeans(both_error[NUM_EXPERTS+1:NUM_TOTAL,to_select],na.rm=T)
mean_acc_all = as.data.frame(rbind(mean_acc_e_e, mean_acc_e_a,
mean_acc_a_e, mean_acc_a_a,
mean_acc_b_e, mean_acc_b_a))
colnames(mean_acc_all) = as.character(k)
mean_acc_all$reco_group = c('Experts only', 'Experts only',
'Amateurs only', 'Amateurs only',
'Both','Both')
mean_acc_all$reco_group <- factor(mean_acc_all$reco_group, levels = c("Amateurs only", "Experts only", "Both"))
mean_acc_all$stats_group = c('Expert', 'Amateur',
'Expert', 'Amateur',
'Expert', 'Amateur')
keycol = 'k_value'
valuecol = 'Accuracy'
longform_mean_acc_all = gather(mean_acc_all, 'k_value', 'Accuracy', as.character(k))
longform_mean_acc_all$k_value = factor(longform_mean_acc_all$k_value,
levels=as.character(k))
longform_mean_acc_all$k_value = strtoi(longform_mean_acc_all$k_value)
grouped_accuracies = ggplot(data=longform_mean_acc_all, aes(x=as.numeric(k_value), y=as.numeric(Accuracy))) +
geom_line(aes(linetype=reco_group, color=stats_group), size=1.5, alpha=.8) +
scale_linetype_manual(values=c("dotdash","solid", "dashed")) +
scale_color_viridis(option='A',begin=COLOR_START,
end=.2, discrete=TRUE) +
theme_bw() + labs(x='k nearest neighbours',y='Accuracy') +
scale_x_continuous(breaks = c(1,2,3,5,7,9,11,13,15,17,19),
limits = c(1,19),expand = c(0.02, 0.02)) +
theme(aspect.ratio =1,
legend.position = c(0.725,0.125),
legend.title = element_text(size = 14),
legend.text = element_text(size = 14),
legend.box="horizontal") +
scale_y_continuous(limits=c(.5,.85)) +
guides(color=guide_legend(title="User")) +
guides(linetype=guide_legend(title="Recommender")) +
theme(axis.text=element_text(size=20),
axis.title=element_text(size=22))
grouped_accuracies
#### Figures for main paper : figure 2b ####
acc_figure_df <- data.frame()
stats_df$k_5_both = both_error[,26]
stats_df$k_5_experts = experts_error[,26]
stats_df$k_5_amateurs = amateurs_error[,26]
temp_df = as.data.frame(stats_df$'k_5_experts')
temp_df$ex_am = c(rep('Expert',NUM_EXPERTS), rep('Amateur', NUM_AMATEURS))
temp_df$strategy = rep('Experts only', NUM_TOTAL)
temp_df$ids = 1:NUM_TOTAL
colnames(temp_df) = c('accuracy', 'ex_am', 'strategy', 'id')
acc_figure_df = rbind(acc_figure_df, temp_df)
temp_df = as.data.frame(stats_df$'k_5_amateurs')
temp_df$ex_am = c(rep('Expert',NUM_EXPERTS), rep('Amateur', NUM_AMATEURS))
temp_df$strategy = rep('Amateurs only', NUM_TOTAL)
temp_df$ids = 1:NUM_TOTAL
colnames(temp_df) = c('accuracy', 'ex_am', 'strategy', 'id')
acc_figure_df = rbind(acc_figure_df, temp_df)
temp_df = as.data.frame(stats_df$'k_5_both')
temp_df$ex_am = c(rep('Expert',NUM_EXPERTS), rep('Amateur', NUM_AMATEURS))
temp_df$strategy = rep('Both', NUM_TOTAL)
temp_df$ids = 1:NUM_TOTAL
colnames(temp_df) = c('accuracy', 'ex_am', 'strategy', 'id')
acc_figure_df = rbind(acc_figure_df, temp_df)
acc_figure_df$strategy = as.factor(acc_figure_df$strategy)
acc_figure_df$strategy <- factor(acc_figure_df$strategy,levels = c('Amateurs only','Experts only','Both'))
acc_fig = ggplot(data=acc_figure_df, aes(x=strategy, y=accuracy)) +
geom_point(aes(fill=ex_am, group=as.factor(id)), position = position_dodge(0.2), shape=21,
size=2.5) +
geom_line(aes(group=as.factor(id)), colour="gray",alpha=0.2,position = position_dodge(0.2)) +
scale_fill_viridis_d(begin=COLOR_START,end=COLOR_END, option='C') + theme_bw() +
labs(x='Source of recommendations',y='Accuracy') +
guides(fill=guide_legend(title="")) +
theme(aspect.ratio = 1,legend.position = c(0.2,0.9),
legend.title = element_text(size = 14),
legend.text = element_text(size = 14)) +
scale_y_continuous(position = "right", limits=c(.5,.85)) +
theme(legend.key.size=unit(.25,'cm')) +
theme(axis.text=element_text(size=20),
axis.title=element_text(size=22))
g1 = ggplotGrob(grouped_accuracies)
g2 = ggplotGrob(acc_fig)
g = grid.arrange(g1,g2,nrow=1)
ggsave(file.path('results', 'visualization',
'fig_2.png'), g, scale=1.35)
#### Supplementary figures : figure 6 ####
both_error = read.table(file.path('results','simulations',
'both','performance.csv'),header=FALSE,sep=' ')
experts_error = read.table(file.path('results','simulations',
'experts','performance.csv'),header=FALSE,sep=' ')
amateurs_error = read.table(file.path('results','simulations',
'amateurs','performance.csv'),header=FALSE,sep=' ')
# pick out k = 3,5,9,13 for all errors
pick_indices = c(seq(2*length(rho)+1, (2*length(rho) + length(rho))),
seq(3*length(rho)+1, (3*length(rho) + length(rho))),
seq(5*length(rho)+1, (5*length(rho) + length(rho))),
seq(6*length(rho)+1, (6*length(rho) + length(rho))))
mean_acc_e_e = colMeans(experts_error[1:NUM_EXPERTS,pick_indices],na.rm=T) # experts recommending experts
mean_acc_e_a = colMeans(experts_error[NUM_EXPERTS+1:NUM_TOTAL,pick_indices],na.rm=T) # ex reco amateurs
mean_acc_a_e = colMeans(amateurs_error[1:NUM_EXPERTS,pick_indices],na.rm=T)
mean_acc_a_a = colMeans(amateurs_error[NUM_EXPERTS+1:NUM_TOTAL,pick_indices],na.rm=T)
mean_acc_b_e = colMeans(both_error[1:NUM_EXPERTS,pick_indices],na.rm=T)
mean_acc_b_a = colMeans(both_error[NUM_EXPERTS+1:NUM_TOTAL,pick_indices],na.rm=T)
mean_acc_all = as.data.frame(rbind(mean_acc_e_e, mean_acc_e_a,
mean_acc_a_e, mean_acc_a_a,
mean_acc_b_e, mean_acc_b_a))
mean_acc_all = as.matrix(mean_acc_all)
longform_mean_acc_all = data.frame()
reco_group = c('Experts only', 'Experts only',
'Amateurs only', 'Amateurs only',
'Both','Both')
stats_group = c('Expert', 'Amateur',
'Expert', 'Amateur',
'Expert', 'Amateur')
chosen_ks = c('k = 3','k = 5','k = 9','k = 13')
for (g_type in 1:dim(mean_acc_all)[1]){
for (r_value in 1:dim(mean_acc_all)[2]) {
longform_mean_acc_all = rbind(longform_mean_acc_all,
c(mean_acc_all[g_type, r_value],
reco_group[g_type],
stats_group[g_type],
rho[(r_value-1)%%length(rho) + 1],
chosen_ks[ceiling(r_value/length(rho))]))
}
}
colnames(longform_mean_acc_all) = c('Accuracy', 'reco_group', 'stats_group', 'rho_value', 'k_value')
longform_mean_acc_all$rho_value = as.double(longform_mean_acc_all$rho_value)
longform_mean_acc_all$k_value = factor(longform_mean_acc_all$k_value,
levels=chosen_ks)
grouped_accuracies = ggplot(data=longform_mean_acc_all,
aes(x=as.numeric(rho_value), y=as.numeric(Accuracy))) +
facet_wrap(vars(k_value), nrow=2, ncol=2) +
geom_line(aes(linetype=reco_group, color=stats_group), size=.8, alpha=.8) +
scale_linetype_manual(values=c("dotdash","solid", "dashed")) +
scale_color_viridis(option='A',begin=COLOR_START,
end=.2, discrete=TRUE) +
theme_bw() + labs(x='Weighting parameter (rho)',y='Accuracy') +
guides(color=guide_legend(title="User")) +
guides(linetype=guide_legend(title="Recommender")) +
theme(axis.text=element_text(size=20),
axis.title=element_text(size=22),
strip.text.x = element_text(size = 11),
legend.title = element_text(size = 14),
legend.text = element_text(size = 14))
grouped_accuracies
ggsave(file.path('results','visualization', 'fig_6.png'))
knitr::plot_crop(file.path('results','visualization', 'fig_6.png'))
#### scratch plot ####
baseline_error = read.table(file.path('results','simulations',
'both','baseline.csv'),header=FALSE,sep=' ')
View(baseline_error)
#### scratch plot ####
baseline_error = read.table(file.path('results','simulations',
'both','baseline.csv'),header=FALSE,sep=' ')
View(baseline_error)
mean(baseline_error)
View(baseline_error)
colMeans(baseline_error)
colMeans(both_error)
max(colMeans(both_error))
#### scratch plot 2 ####
both_error = read.table(file.path('results','simulations',
'both','performance.csv'),header=FALSE,sep=' ')
both_error$X = 1:NUM_TOTAL
both_error = gather(both_error, key='k', value='v', -X)
View(both_error)
View(experts_error)
both_error = gather(both_error, key='k', value='v')
#### scratch plot 2 ####
both_error = read.table(file.path('results','simulations',
'both','performance.csv'),header=FALSE,sep=' ')
both_error = colMeans(both_error)
both_error = gather(as.data.frame(both_error), key='k', value='v')
View(both_error)
both_error$k = rep(k, each=length(rho))
both_error$rho = rep(rho, length(k))
View(both_error)
heatmap_1 = ggplot(both_error, aes(x=k, y=rho, fill=v)) + geom_tile()
heatmap_1
k_levels = as.character(k)
r_levels = as.character(rho)
heatmap_1 = ggplot(both_error, aes(x=factor(k, levels=k_levels),
y=factor(rho, levels=r_levels), fill=v)) + geom_tile()
heatmap_1
heatmap_1 = ggplot(both_error, aes(x=factor(k, levels=k_levels),
y=factor(rho, levels=r_levels), fill=v)) +
geom_tile() +
scale_fill_viridis()
heatmap_1
both_error = both_error[both_error$k < 23,]
k_levels = as.character(k)
r_levels = as.character(rho)
heatmap_1 = ggplot(both_error, aes(x=factor(k, levels=k_levels),
y=factor(rho, levels=r_levels), fill=v)) +
geom_tile() +
scale_fill_viridis()
heatmap_1
winning_strategy = which.max(as.matrix(both_error))
winning_strategy
winning_strategy = data.frame()
winning_strategy$max <- do.call(pmax, both_error)
winning_strategy = rowMaxs(both_error)
winning_strategy = rowMaxs(as.matrix(both_error))
#### scratch plot 2 ####
both_error = read.table(file.path('results','simulations',
'both','performance.csv'),header=FALSE,sep=' ')
winning_strategy = rowMaxs(as.matrix(both_error))
winning_strategy = as.data.frame(rowMaxs(as.matrix(both_error)))
colnames(winning_strategy) = 'max_accuracy'
winning_strategy$idx = which(both_error = winning_strategy$max_accuracy)
winning_strategy$idx = which(both_error == winning_strategy$max_accuracy)
134*2
temp = both_error == winning_strategy$max_accuracy
View(temp)
which(temp)
temp = which(temp, arr.ind=T)
View(temp)
both_error = as.matrix(both_error)
#### scratch plot 2 ####
both_error = read.table(file.path('results','simulations',
'both','performance.csv'),header=FALSE,sep=' ')
both_error = as.matrix(both_error)
for (u in 1:(NUM_TOTAL+1)){
print(which.max(both_error[u,]))
}
winning_strategy = data.frame()
for (u in 1:NUM_TOTAL){
winning_strategy = rbind(winning_strategy,
c(u, which.max(both_error[u,])))
}
View(winning_strategy)
winning_strategy = data.frame()
for (u in 1:NUM_TOTAL){
winning_strategy = rbind(winning_strategy,
c(u,
k[ceiling(which.max(both_error[u,])/length(rho))]))
}
View(winning_strategy)
winning_strategy = data.frame()
for (u in 1:NUM_TOTAL){
winning_strategy = rbind(winning_strategy,
c(u,
k[ceiling(which.max(both_error[u,])/length(rho))],
rho[which.max(both_error[u,])%%length(rho)]))
}
View(winning_strategy)
winning_strategy = data.frame()
for (u in 1:NUM_TOTAL){
winning_strategy = rbind(winning_strategy,
c(u,
k[ceiling(which.max(both_error[u,])/length(rho))],
rho[which.max(both_error[u,])%%length(rho)] ))
}
warnings()
winning_strategy = data.frame()
rho[which.max(both_error[1,])%%length(rho)]
rho[which.max(both_error[2,])%%length(rho)]
rho[which.max(both_error[10,])%%length(rho)]
rho[which.max(both_error[20,])%%length(rho)]
which.max(both_error[1,])
which.max(both_error[1,])%%length(rho)
rho[which.max(both_error[1,])%%length(rho)]
as.numeric(rho[which.max(both_error[1,])%%length(rho)])
rho
temp_rho = as.character(rho)
both_error = as.matrix(both_error)
winning_strategy = data.frame()
temp_rho = as.character(rho)
for (u in 1:NUM_TOTAL){
winning_strategy = rbind(winning_strategy,
c(u,
k[ceiling(which.max(both_error[u,])/length(rho))],
temp_rho[which.max(both_error[u,])%%length(rho)] ))
}
View(winning_strategy)
both_error = as.matrix(both_error)
winning_strategy = data.frame()
temp_rho = as.character(rho)
for (u in 1:NUM_TOTAL){
winning_strategy = rbind(winning_strategy,
c(u,
k[ceiling(which.max(both_error[u,])/length(rho))]))
print(temp_rho[which.max(both_error[u,])%%length(rho)])
}
both_error = as.matrix(both_error)
winning_strategy = data.frame()
temp_rho = as.character(rho)
for (u in 1:NUM_TOTAL){
winning_strategy = rbind(winning_strategy,
c(u,
k[ceiling(which.max(both_error[u,])/length(rho))]))
print(temp_rho[which.max(both_error[u,])%%length(rho) + 1])
}
both_error = as.matrix(both_error)
winning_strategy = data.frame()
for (u in 1:NUM_TOTAL){
winning_strategy = rbind(winning_strategy,
c(u,
k[ceiling(which.max(both_error[u,])/length(rho))]),
rho[which.max(both_error[u,])%%length(rho) + 1])
}
View(winning_strategy)
View(winning_strategy)
both_error = as.matrix(both_error)
winning_strategy = data.frame()
for (u in 1:NUM_TOTAL){
winning_strategy = rbind(winning_strategy,
c(u,
k[ceiling(which.max(both_error[u,])/length(rho))],
rho[which.max(both_error[u,])%%length(rho) + 1]))
}
View(winning_strategy)
both_error = as.matrix(both_error)
winning_strategy = data.frame()
for (u in 1:NUM_TOTAL){
winning_strategy = rbind(winning_strategy,
c(u,
max(both_error[u,]),
k[ceiling(which.max(both_error[u,])/length(rho))],
rho[which.max(both_error[u,])%%length(rho) + 1]))
}
View(winning_strategy)
colnames(winning_strategy) = c('Rater','Accuracy','k','rho')
baseline_error = read.table(file.path('results','simulations',
'both','baseline_csv'),header=FALSE,sep=' ')
baseline_error = read.table(file.path('results','simulations',
'both','baseline.csv'),header=FALSE,sep=' ')
both_error = as.matrix(both_error)
winning_strategy = data.frame()
for (u in 1:NUM_TOTAL){
winning_strategy = rbind(winning_strategy,
c(u,
max(both_error[u,]),
k[ceiling(which.max(both_error[u,])/length(rho))],
rho[which.max(both_error[u,])%%length(rho) + 1]))
}
colnames(winning_strategy) = c('Rater','Accuracy','k','rho')
winning_strategy$baseline = basline_error
winning_strategy$baseline = baseline_error
View(winning_strategy)
View(winning_strategy)
baseline_error = read.table(file.path('results','simulations',
'both','baseline.csv'),header=FALSE,sep=' ')
both_error = as.matrix(both_error)
winning_strategy = data.frame()
for (u in 1:NUM_TOTAL){
winning_strategy = rbind(winning_strategy,
c(u,
max(both_error[u,]),
k[ceiling(which.max(both_error[u,])/length(rho))],
rho[which.max(both_error[u,])%%length(rho) + 1],
baseline_error[u,]))
}
View(winning_strategy)
colnames(winning_strategy) = c('Rater','Accuracy','k','rho', 'baseline')
View(winning_strategy)
strategy_hist = ggplot(winning_strategy, aes(x=k)) + geom_histogram()
strategy_hist
strategy_hist = ggplot(winning_strategy, aes(x=factor(k))) + geom_histogram()
strategy_hist
strategy_hist = ggplot(winning_strategy, aes(x=as.factor(k))) + geom_histogram()
strategy_hist
strategy_hist = ggplot(winning_strategy, aes(x=as.factor(k))) +
geom_histogram(stat='count')
strategy_hist
strategy_hist = ggplot(winning_strategy, aes(x=as.factor(rho))) +
geom_histogram(stat='count')
strategy_hist
strategy_hist = ggplot(winning_strategy, aes(x=as.factor(k))) +
geom_histogram(stat='count')
strategy_hist
strategy_hist = ggplot(winning_strategy, aes(x=as.factor(k),
y=as.factor(rho),
fill=Accuracy)) +
geom_tile()
strategy_hist
